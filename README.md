#  Post Training of LLM
&emsp;&emsp;本项目是一个围绕 **DeepLearning.AI** 出品的 *Post-Training for LLMs* 系列课程，为国内学习者量身打造的中文翻译与知识整理教程。项目提供课程内容翻译、知识点梳理和示例代码等内容，旨在降低语言门槛，让更多学生、研究人员和开发者系统掌握大语言模型（LLM）后训练阶段的核心技术与实践方法。

&emsp;&emsp;本项目的主要内容包括：

1. **课程内容翻译**：精准翻译课程讲解内容，确保技术细节准确传达；
2. **知识结构化整理**：梳理并总结 LLM 后训练核心概念，如 SFT、DPO、OnlineRL 等；
3. **配套示例与代码**：为关键知识点补充可运行的 Python 代码；


&emsp;&emsp;**项目的核心目标** 是帮助国内学习者系统学习国际前沿的 LLM 后训练技术，缩小信息差距，并推动 LLM 技术在更多实际场景中落地应用。任何人都可以提出 Issue 或提交 PR，共同完善和维护这个项目。

---

## 项目意义

> 什么是 LLM Post-Training？
>
> **Post-Training** 是指在预训练之后对大语言模型进行进一步优化与对齐的过程，包括监督微调（SFT）、直接偏好优化（DPO）等。这些技术可以让模型更符合人类价值观、任务需求和使用场景。

&emsp;&emsp;当前 LLM 技术快速发展，但高质量的中文学习资料仍较少，尤其是在 **后训练阶段** 的系统化内容方面。本项目旨在将 DeepLearning.AI 的高质量课程引入中文世界，让更多开发者与学生能直接接触到国际一线的 LLM 后训练知识，并在自己的项目中加以实践。

---

## 项目受众

本项目适合以下学习者：

- 对 LLM 优化与应用感兴趣。
- 希望深入理解并掌握模型后训练方法的。
- 希望结合后训练技术打造领域专用模型的 。
- 以及最广大、最普通的学生群体

### 他们能获得的收获

- 系统化掌握 LLM 后训练方法与流程。
- 通过示例代码快速上手实践。
- 为微调、对齐、RAG 等下游任务打下坚实基础。
- 为构建领域专有模型提供帮助。


## 学习建议

1. **先掌握基础概念** —— 先理解 SFT、DPO等核心算法原理；
2. **再结合示例实践** —— 跟随项目中的代码样例动手实验；
3. **最后应用到项目中** —— 将所学方法应用于自己的模型优化任务。


## 目录
*这里写你的项目目录，已完成的部分用添加上跳转链接*
- [第1章](https://github.com/datawhalechina/Post-training-of-LLMs/blob/364baeddafbbf1fb94f08c432c1ec5e233c7d112/docs/chapter1)
  - [1.1 课程介绍]()
  - [1.2 后训练技术介绍]()
- [第2章](https://github.com/datawhalechina/Post-training-of-LLMs/blob/db3d8b98acc47b542ac4ddabbbe633124be24ca3/docs/chapter2)
  - [2.1 监督微调基础理论](https://github.com/datawhalechina/Post-training-of-LLMs/blob/364baeddafbbf1fb94f08c432c1ec5e233c7d112/docs/chapter2/chapter2_1)
  - [2.2 监督微调实践](https://github.com/datawhalechina/Post-training-of-LLMs/blob/364baeddafbbf1fb94f08c432c1ec5e233c7d112/docs/chapter2/chapter2_2)
- [第3章](https://github.com/datawhalechina/Post-training-of-LLMs/blob/db3d8b98acc47b542ac4ddabbbe633124be24ca3/docs/chapter3)
  - [3.1 直接偏好优化基础理论](https://github.com/datawhalechina/Post-training-of-LLMs/blob/dc4f411b5e1a0edf92289269b682c3ab421a0a2b/docs/chapter3/chapter3_1)
  - [3.2 直接偏好优化实践](https://github.com/datawhalechina/Post-training-of-LLMs/blob/364baeddafbbf1fb94f08c432c1ec5e233c7d112/docs/chapter3/chapter3_2)
- [第4章](https://github.com/datawhalechina/Post-training-of-LLMs/blob/364baeddafbbf1fb94f08c432c1ec5e233c7d112/docs/chapter4)
  - [4.1 在线强化学习基础理论]()
  - [4.2 在线强化学习实践](https://github.com/datawhalechina/Post-training-of-LLMs/blob/be674beded58fd9b538ccd8e134d39fa64dee746/docs/chapter4/chapter4_2)
- [第5章](https://github.com/datawhalechina/Post-training-of-LLMs/blob/364baeddafbbf1fb94f08c432c1ec5e233c7d112/docs/chapter5)

## 贡献者名单

| 姓名 | 职责 | 简介 |
| :----| :---- | :---- |
| 小明 | 项目负责人 | 一个理想主义者 |
| 小红 | 第1章贡献者 | 小明的朋友 |
| 小强 | 第2章贡献者 | 小明的朋友 |

*注：表头可自定义，但必须在名单中标明项目负责人*

## 参与贡献

- 如果你发现了一些问题，可以提Issue进行反馈，如果提完没有人回复你可以联系[保姆团队](https://github.com/datawhalechina/DOPMC/blob/main/OP.md)的同学进行反馈跟进~
- 如果你想参与贡献本项目，可以提Pull request，如果提完没有人回复你可以联系[保姆团队](https://github.com/datawhalechina/DOPMC/blob/main/OP.md)的同学进行反馈跟进~
- 如果你对 Datawhale 很感兴趣并想要发起一个新的项目，请按照[Datawhale开源项目指南](https://github.com/datawhalechina/DOPMC/blob/main/GUIDE.md)进行操作即可~

## 关注我们

<div align=center>
<p>扫描下方二维码关注公众号：Datawhale</p>
<img src="https://raw.githubusercontent.com/datawhalechina/pumpkin-book/master/res/qrcode.jpeg" width = "180" height = "180">
</div>

## LICENSE

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。

*注：默认使用CC 4.0协议，也可根据自身项目情况选用其他协议*
